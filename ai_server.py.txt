from flask import Flask, request, jsonify
from gpt4all import GPT4All
import os

app = Flask(__name__)

# Load AI model (make sure this model file exists in your repo)
llm = GPT4All("orca-mini-3b.ggmlv3.q4_0.bin")

@app.route("/chat", methods=["POST"])
def chat():
    data = request.json
    user_text = data["text"]
    response = llm.generate(user_text, max_tokens=100)
    return jsonify({"reply": response})

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))  # Render assigns port
    app.run(host="0.0.0.0", port=port)
